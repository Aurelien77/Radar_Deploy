{
  "radar_name": "Veille IA 2024",
  "radar_type": "veilleIA",
  
  "sections": {
    "1": "IA Générative (Texte)",
    "2": "IA Générative (Images)",
    "3": "Vision par Ordinateur",
    "4": "NLP / LLM / Chatbots",
    "5": "ML & Data Science",
    "6": "Agents Autonomes",
    "7": "IA Audio / Speech",
    "8": "MLOps & Infrastructure IA"
  },
  
  "rings": {
    "A ": [0, 50],
    "B": [51, 75],
    "C": [76, 100]
  },
  
  "ring_colors": {
    "A ": "#93c47d",
    "B": "#f6b26b",
    "C": "#e06666"
  },
  
  "anti_collision": true,
  "min_distance_between_points": 3.5,
  
  "technologies": [
    {
      "name": "ChatGPT",
      "section": 1,
      "distance": 20,
      "position": 50,
      "description": "# ChatGPT (OpenAI)\n\n**Type**: Large Language Model\n**Version actuelle**: GPT-4\n\n## Capacités\n- Génération de texte de haute qualité\n- Compréhension contextuelle avancée\n- Raisonnement multi-étapes\n- Code generation\n\n## Use cases\n- Assistance à la rédaction\n- Chatbots intelligents\n- Analyse de documents\n- Génération de code"
    },
    {
      "name": "Claude",
      "section": 1,
      "distance": 22,
      "position": 55,
      "description": "# Claude (Anthropic)\n\n**Type**: Large Language Model\n**Version actuelle**: Claude 3.5 Sonnet\n\n## Avantages\n- Contexte étendu (200K tokens)\n- Sécurité et éthique intégrées\n- Excellente précision\n- API simple d'utilisation\n\n## Points forts\n- Analyse de longs documents\n- Raisonnement complexe\n- Code quality"
    },
    {
      "name": "Gemini",
      "section": 1,
      "distance": 25,
      "position": 45,
      "description": "# Gemini (Google)\n\n**Type**: Multimodal AI Model\n\n## Capacités\n- Traitement texte, image, audio, vidéo\n- Intégration Google Workspace\n- Multilingue avancé\n\n## Use cases\n- Applications multimodales\n- Analyse de contenus mixtes"
    },
    {
      "name": "Llama 3",
      "section": 1,
      "distance": 30,
      "position": 50,
      "description": "# Llama 3 (Meta)\n\n**Type**: Open Source LLM\n\n## Avantages\n- Open source et gratuit\n- Peut être auto-hébergé\n- Bonnes performances\n\n## Tailles disponibles\n- 8B, 70B, 405B paramètres"
    },
    {
      "name": "DALL-E 3",
      "section": 2,
      "distance": 25,
      "position": 40,
      "description": "# DALL-E 3 (OpenAI)\n\n**Type**: Text-to-Image Generation\n\n## Capacités\n- Génération d'images haute qualité\n- Compréhension fine des prompts\n- Style artistique varié\n- Édition d'images\n\n## Intégration\n- API OpenAI\n- ChatGPT Plus"
    },
    {
      "name": "Midjourney",
      "section": 2,
      "distance": 23,
      "position": 60,
      "description": "# Midjourney\n\n**Type**: AI Art Generation\n\n## Points forts\n- Qualité artistique exceptionnelle\n- Styles variés et créatifs\n- Communauté active\n\n## Interface\n- Discord bot\n- Interface web (alpha)"
    },
    {
      "name": "Stable Diffusion",
      "section": 2,
      "distance": 28,
      "position": 50,
      "description": "# Stable Diffusion\n\n**Type**: Open Source Image Generation\n\n## Avantages\n- Open source\n- Peut être auto-hébergé\n- Personnalisable (LoRA, fine-tuning)\n- GPU accessible\n\n## Versions\n- SDXL, SD 3.5"
    },
    {
      "name": "YOLOv8",
      "section": 3,
      "distance": 30,
      "position": 50,
      "description": "# YOLOv8 (Ultralytics)\n\n**Type**: Object Detection\n\n## Capacités\n- Détection d'objets en temps réel\n- Segmentation d'instances\n- Pose estimation\n- Classification\n\n## Performance\n- Rapide (30+ FPS)\n- Précis\n- Facile à entraîner"
    },
    {
      "name": "SAM",
      "section": 3,
      "distance": 35,
      "position": 45,
      "description": "# Segment Anything Model (Meta)\n\n**Type**: Image Segmentation\n\n## Innovation\n- Segmentation zero-shot\n- Fonctionne sur n'importe quelle image\n- Précision remarquable\n\n## Use cases\n- Édition d'images\n- Annotation automatique\n- Vision robotique"
    },
    {
      "name": "OpenCV",
      "section": 3,
      "distance": 15,
      "position": 55,
      "description": "# OpenCV\n\n**Type**: Computer Vision Library\n\n## Capacités\n- Traitement d'images classique\n- Détection de features\n- Tracking d'objets\n- Calibration caméra\n\n## Status\n- Bibliothèque mature et stable\n- Utilisée en production"
    },
    {
      "name": "LangChain",
      "section": 4,
      "distance": 35,
      "position": 45,
      "description": "# LangChain\n\n**Type**: LLM Application Framework\n\n## Fonctionnalités\n- Chaînes de prompts\n- Agents avec tools\n- Memory management\n- RAG (Retrieval Augmented Generation)\n\n## Intégrations\n- OpenAI, Anthropic, etc.\n- Vector databases\n- APIs externes"
    },
    {
      "name": "LlamaIndex",
      "section": 4,
      "distance": 40,
      "position": 55,
      "description": "# LlamaIndex\n\n**Type**: Data Framework for LLM\n\n## Spécialité\n- RAG optimisé\n- Indexation de documents\n- Recherche sémantique\n- Query engines\n\n## Use cases\n- Chatbots sur données privées\n- Q&A systems\n- Document analysis"
    },
    {
      "name": "Hugging Face Transformers",
      "section": 4,
      "distance": 25,
      "position": 50,
      "description": "# Hugging Face Transformers\n\n**Type**: ML Library\n\n## Capacités\n- Accès à 100K+ modèles\n- Fine-tuning simplifié\n- Inference optimisée\n- Multi-frameworks (PyTorch, TF)\n\n## Modèles populaires\n- BERT, GPT, T5, LLaMA, etc."
    },
    {
      "name": "TensorFlow",
      "section": 5,
      "distance": 40,
      "position": 50,
      "description": "# TensorFlow (Google)\n\n**Type**: ML Framework\n\n## Capacités\n- Deep learning\n- Production deployment\n- Mobile (TFLite)\n- JavaScript (TF.js)\n\n## Écosystème\n- TensorBoard\n- TF Serving\n- TF Extended (TFX)"
    },
    {
      "name": "PyTorch",
      "section": 5,
      "distance": 38,
      "position": 55,
      "description": "# PyTorch (Meta)\n\n**Type**: ML Framework\n\n## Points forts\n- Recherche et prototypage\n- API pythonique\n- Dynamic computation graph\n- Communauté active\n\n## Adoption\n- Standard de la recherche\n- Production avec TorchServe"
    },
    {
      "name": "scikit-learn",
      "section": 5,
      "distance": 20,
      "position": 45,
      "description": "# scikit-learn\n\n**Type**: ML Library (Classical ML)\n\n## Algorithmes\n- Classification, régression\n- Clustering\n- Dimensionality reduction\n- Preprocessing\n\n## Usage\n- ML classique (non deep learning)\n- Production stable"
    },
    {
      "name": "AutoGPT",
      "section": 6,
      "distance": 60,
      "position": 50,
      "description": "# AutoGPT\n\n**Type**: Autonomous Agent\n\n## Concept\n- Agent autonome basé sur GPT-4\n- Décompose et exécute des tâches\n- Utilise des tools\n\n## Status\n- Expérimental\n- Concept prometteur\n- Limitations actuelles"
    },
    {
      "name": "LangGraph",
      "section": 6,
      "distance": 55,
      "position": 60,
      "description": "# LangGraph\n\n**Type**: Agent Framework\n\n## Fonctionnalités\n- Orchestration d'agents\n- State machines\n- Multi-agent systems\n- Workflows complexes\n\n## Integration\n- LangChain ecosystem"
    },
    {
      "name": "CrewAI",
      "section": 6,
      "distance": 58,
      "position": 40,
      "description": "# CrewAI\n\n**Type**: Multi-Agent Framework\n\n## Concept\n- Équipes d'agents IA\n- Collaboration entre agents\n- Rôles et tâches\n\n## Use cases\n- Workflows complexes\n- Automatisation avancée"
    },
    {
      "name": "Whisper",
      "section": 7,
      "distance": 28,
      "position": 45,
      "description": "# Whisper (OpenAI)\n\n**Type**: Speech Recognition\n\n## Capacités\n- Transcription audio\n- Multilingue (99 langues)\n- Robuste au bruit\n- Punctuation automatique\n\n## Modèles\n- tiny, base, small, medium, large\n- Open source"
    },
    {
      "name": "ElevenLabs",
      "section": 7,
      "distance": 32,
      "position": 55,
      "description": "# ElevenLabs\n\n**Type**: Text-to-Speech\n\n## Points forts\n- Voix ultra-réalistes\n- Clonage de voix\n- Multilingue\n- Contrôle émotionnel\n\n## Use cases\n- Audiobooks\n- Voiceovers\n- Assistants vocaux"
    },
    {
      "name": "Bark",
      "section": 7,
      "distance": 55,
      "position": 50,
      "description": "# Bark (Suno AI)\n\n**Type**: Audio Generation\n\n## Capacités\n- Text-to-audio\n- Musique, effets sonores\n- Voix avec émotions\n- Open source\n\n## Particularité\n- Génération créative\n- Non limité à la parole"
    },
    {
      "name": "MLflow",
      "section": 8,
      "distance": 45,
      "position": 50,
      "description": "# MLflow\n\n**Type**: MLOps Platform\n\n## Composants\n- Tracking (expériences)\n- Projects (packaging)\n- Models (registry)\n- Model serving\n\n## Avantages\n- Open source\n- Framework agnostic\n- Production ready"
    },
    {
      "name": "Weights & Biases",
      "section": 8,
      "distance": 48,
      "position": 60,
      "description": "# Weights & Biases (W&B)\n\n**Type**: ML Experiment Tracking\n\n## Fonctionnalités\n- Visualisation d'expériences\n- Hyperparameter tuning\n- Model registry\n- Collaboration d'équipe\n\n## Interface\n- Dashboard web puissant\n- Intégrations multiples"
    },
    {
      "name": "Kubeflow",
      "section": 8,
      "distance": 65,
      "position": 45,
      "description": "# Kubeflow\n\n**Type**: ML on Kubernetes\n\n## Capacités\n- Orchestration de pipelines ML\n- Distributed training\n- Model serving\n- Experiment tracking\n\n## Complexité\n- Enterprise-grade\n- Courbe d'apprentissage"
    },
    {
      "name": "DVC",
      "section": 8,
      "distance": 40,
      "position": 55,
      "description": "# DVC (Data Version Control)\n\n**Type**: Version Control for ML\n\n## Fonctionnalités\n- Versioning de datasets\n- Versioning de modèles\n- Pipelines ML\n- Git-like interface\n\n## Use cases\n- Reproducibilité\n- Collaboration data science"
    },
    {
      "name": "Ray",
      "section": 8,
      "distance": 52,
      "position": 40,
      "description": "# Ray\n\n**Type**: Distributed Computing\n\n## Composants\n- Ray Core (distributed Python)\n- Ray Train (distributed training)\n- Ray Serve (model serving)\n- Ray Tune (hyperparameter tuning)\n\n## Performance\n- Scaling horizontal\n- Production-grade"
    }
  ]
}